{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9i36Uy2miiM6"
      },
      "source": [
        "<div style=\"display: flex; align-items: center; gap: 40px;\">\n",
        "\n",
        "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSkez75fZoo82SccEXRMVRlj9sZsQifRUhURQ&s\" width=\"240\">\n",
        "<img src=\"https://pbs.twimg.com/profile_images/1783589223406415872/3KMxGGrF_400x400.jpg\" width=\"130\">\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<div>\n",
        "  <h2>Cerebras Inference</h2>\n",
        "  <p>Cerebras Systems builds the world's largest computer chip - the Wafer Scale Engine (WSE) - designed specifically for AI workloads. This cookbook provides comprehensive examples, tutorials, and best practices for developing and deploying AI models using Cerebras infrastructure, including both training on WSE clusters and fast inference via Cerebras Cloud.</p>\n",
        "\n",
        "  <h2>LiteLLM 🚅</h2>\n",
        "    <p>LiteLLM simplifies access to 100+ large language models (LLMs) with a unified API. It enables easy model integration, spend tracking, rate-limiting, fallbacks, and observability—helping developers manage LLMs like OpenAI, Anthropic, Groq, Cohere, Google, and more from a single interface.</p>\n",
        "  </div>\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1KrVzIjva5AqYwuaciHBNY8eIkrnIx1VJ?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ihV9u0GjyoE"
      },
      "source": [
        "## Get Your API Keys\n",
        "\n",
        "Before you begin, make sure you have:\n",
        "\n",
        "1. A Cerebras API key (Get yours at [Cerebras Cloud](https://cloud.cerebras.ai/))\n",
        "2. Basic familiarity with Python and Jupyter notebooks\n",
        "\n",
        "This notebook is designed to run in Google Colab, so no local Python installation is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3ENRkyQj3Ql"
      },
      "source": [
        "###Cerebras using LiteLLM 🚅"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb1D4-IgkDJ6"
      },
      "source": [
        "###Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wr9gUotyihbT",
        "outputId": "4a3719ac-0609-40ba-d897-eaa0bd2aaf80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.3/272.3 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q litellm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UiR-Xy2kU0F"
      },
      "source": [
        "###Setup API Keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PK09HAeAkXqn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"CEREBRAS_API_KEY\"] = userdata.get(\"CEREBRAS_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmSHlwQBkcKE"
      },
      "source": [
        "###Initialize Cerebras Model via LiteLLM 🚅:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN_VubTWkoJq",
        "outputId": "f8f5cb65-771b-486c-a0b7-af5d047e7b0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cerebras is a company that specializes in developing high-performance computing systems for artificial intelligence (AI) and machine learning (ML) workloads. They achieve ultra-fast inference speeds through a combination of innovative hardware and software designs. Here are some key factors that contribute to their exceptional performance:\n",
            "\n",
            "1. **Wafer-Scale Engine (WSE)**: Cerebras' flagship product is the Wafer-Scale Engine, a massive chip that integrates thousands of processing cores, memory, and interconnects on a single wafer of silicon. This design eliminates the need for traditional chip-to-chip communication, reducing latency and increasing bandwidth.\n",
            "2. **Massive Parallelism**: The WSE features a large number of processing cores, which enables massive parallelism and allows for the simultaneous execution of thousands of instructions. This leads to significant speedups in compute-intensive tasks like matrix multiplication and convolution.\n",
            "3. **High-Bandwidth Memory**: Cerebras' systems incorporate high-bandwidth memory (HBM) that provides fast access to large amounts of data. This memory is optimized for AI and ML workloads, which often require accessing vast amounts of data in parallel.\n",
            "4. **Optimized Interconnects**: The WSE features a high-speed interconnect network that enables fast data transfer between processing cores and memory. This network is optimized for the specific needs of AI and ML workloads, reducing latency and increasing overall system performance.\n",
            "5. **Software Optimization**: Cerebras provides a software development kit (SDK) that allows developers to optimize their AI and ML models for the WSE architecture. This includes tools for model compilation, optimization, and deployment, ensuring that models are executed efficiently on the hardware.\n",
            "6. **Sparse Linear Algebra**: Cerebras' systems are optimized for sparse linear algebra operations, which are common in many AI and ML algorithms. By leveraging the sparsity of matrices, Cerebras can reduce the number of computations required, leading to significant speedups.\n",
            "7. **Mixed-Precision Computing**: Cerebras supports mixed-precision computing, which allows for the use of lower-precision data types (e.g., 16-bit floating-point) for certain operations. This reduces memory bandwidth and compute requirements, resulting in faster execution times.\n",
            "8. **Model Parallelism**: Cerebras' systems can execute multiple models in parallel, allowing for the simultaneous processing of multiple inference requests. This increases overall system throughput and reduces latency.\n",
            "9. **Hardware-Software Co-Design**:\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import litellm\n",
        "\n",
        "api_key = os.environ.get(\"CEREBRAS_API_KEY\")\n",
        "\n",
        "response = litellm.completion(\n",
        "    model=\"cerebras/llama3.3-70b\",\n",
        "    api_key=api_key,\n",
        "    api_base=\"https://api.cerebras.ai/v1\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Explain how Cerebras achieves ultra-fast inference speeds.\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0.7,\n",
        "    max_tokens=500\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['message']['content'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMd7W3-jljhb"
      },
      "source": [
        "###Example 1: Streaming Response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEInYJyXlp8T",
        "outputId": "1a9a059f-0091-480c-a970-3fada8e121cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quantum computing! It's a complex topic, but I'll try to break it down in simple terms.\n",
            "\n",
            "**Classical Computing vs. Quantum Computing**\n",
            "\n",
            "Classical computers, like the one you're using now, use \"bits\" to process information. Bits are either 0 or 1, and they're used to perform calculations and store data. Think of them like light switches – they're either on (1) or off (0).\n",
            "\n",
            "Quantum computers, on the other hand, use \"qubits\" (quantum bits). Qubits are special because they can be both 0 and 1 at the same time, which is known as a \"superposition.\" It's like a light switch that's both on and off simultaneously!\n",
            "\n",
            "**How Qubits Work**\n",
            "\n",
            "Imagine a coin. In classical computing, the coin can either be heads (0) or tails (1). But in quantum computing, the coin can exist in a state where it's both heads AND tails at the same time. This is called a \"superposition.\"\n",
            "\n",
            "When you measure the qubit (like flipping the coin), it \"collapses\" into one state or the other – either 0 or 1. But before measurement, it exists in a mix of both states, which allows quantum computers to process multiple possibilities simultaneously.\n",
            "\n",
            "**Quantum Computing Benefits**\n",
            "\n",
            "This unique property of qubits enables quantum computers to solve certain problems much faster than classical computers. Quantum computers can:\n",
            "\n",
            "1. **Process multiple possibilities at once**: This makes them ideal for tasks like simulating complex systems, factoring large numbers, or optimizing complex problems.\n",
            "2. **Break certain encryption codes**: Quantum computers can potentially break encryption codes that are currently unbreakable by classical computers, which has significant implications for cybersecurity.\n",
            "3. **Improve machine learning**: Quantum computers can speed up certain machine learning tasks, like pattern recognition and clustering.\n",
            "\n",
            "**Simplifying the Complexities**\n",
            "\n",
            "To further simplify things, think of quantum computing like a library. Classical computers are like looking for a specific book in the library one book at a time. Quantum computers are like looking at all the books in the library simultaneously and finding the one you need instantly.\n",
            "\n",
            "**Real-World Applications**\n",
            "\n",
            "Quantum computing has many potential applications, including:\n",
            "\n",
            "1. **Cryptography**: Developing new, quantum-resistant encryption methods to secure online transactions.\n",
            "2. **Optimization**: Improving complex systems, like logistics or energy management, by finding the most efficient solutions.\n",
            "3. **Materials Science**: Simulating the behavior of materials at the molecular level to develop new materials with unique properties.\n",
            "\n",
            "In summary, quantum computing is a new way of processing information that uses qubits, which can exist in multiple states simultaneously. This property allows quantum computers to solve certain problems much faster than classical computers, with potential applications in fields like cryptography, optimization, and materials science.\n",
            "\n",
            "I hope this explanation helped demystify quantum computing for you!"
          ]
        }
      ],
      "source": [
        "response = litellm.completion(\n",
        "    model=\"cerebras/llama3.3-70b\",\n",
        "    api_key=api_key,\n",
        "    api_base=\"https://api.cerebras.ai/v1\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Explain quantum computing in simple terms\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0.8,\n",
        "    max_tokens=1024,\n",
        "    stream=True\n",
        ")\n",
        "\n",
        "for chunk in response:\n",
        "    if chunk.choices[0].delta.content is not None:\n",
        "        print(chunk.choices[0].delta.content, end='')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TljQpjoamM4l"
      },
      "source": [
        "### Example 2: Code Generation with Qwen Coder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nEE9QXPmrrM",
        "outputId": "5e3db983-fefe-4d6f-987d-a31dd0e4220b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```python\n",
            "def binary_search(arr, target):\n",
            "    \"\"\"\n",
            "    Implements binary search algorithm to find a target value in a sorted array.\n",
            "    \n",
            "    Binary search works by repeatedly dividing the search interval in half.\n",
            "    It compares the target value with the middle element of the array and\n",
            "    eliminates half of the remaining elements based on the comparison.\n",
            "    \n",
            "    Args:\n",
            "        arr (list): A sorted list of elements to search through\n",
            "        target: The value to search for in the array\n",
            "    \n",
            "    Returns:\n",
            "        int: The index of the target element if found, otherwise -1\n",
            "    \n",
            "    Time Complexity: O(log n)\n",
            "    Space Complexity: O(1)\n",
            "    \n",
            "    Example:\n",
            "        >>> binary_search([1, 3, 5, 7, 9, 11, 13], 7)\n",
            "        3\n",
            "        >>> binary_search([1, 3, 5, 7, 9, 11, 13], 4)\n",
            "        -1\n",
            "    \"\"\"\n",
            "    \n",
            "    # Initialize the left and right pointers\n",
            "    # left points to the beginning of the array (index 0)\n",
            "    # right points to the end of the array (last index)\n",
            "    left = 0\n",
            "    right = len(arr) - 1\n",
            "    \n",
            "    # Continue searching while the search space is valid (left <= right)\n",
            "    # When left > right, it means the target is not in the array\n",
            "    while left <= right:\n",
            "        \n",
            "        # Calculate the middle index to avoid potential overflow\n",
            "        # Using (left + right) // 2 is also valid for Python, but this method\n",
            "        # is more robust for languages with integer overflow concerns\n",
            "        mid = left + (right - left) // 2\n",
            "        \n",
            "        # If the middle element equals the target, we found it!\n",
            "        # Return the index where the target is located\n",
            "        if arr[mid] == target:\n",
            "            return mid\n",
            "        \n",
            "        # If the middle element is less than the target,\n",
            "        # the target must be in the right half of the array\n",
            "        # Move the left pointer to mid + 1 to search the right half\n",
            "        elif arr[mid] < target:\n",
            "            left = mid + 1\n",
            "        \n",
            "        # If the middle element is greater than the target,\n",
            "        # the target must be in the left half of the array\n",
            "        # Move the right pointer to mid - 1 to search the left half\n",
            "        else:\n",
            "            right = mid - 1\n",
            "    \n",
            "    # If we exit the loop without finding the target,\n",
            "    # it means the target is not present in the array\n",
            "    # Return -1 to indicate that the element was not found\n",
            "    return -1\n",
            "\n",
            "\n",
            "def binary_search_recursive(arr, target, left=0, right=None):\n",
            "    \"\"\"\n",
            "    Implements recursive version of binary search algorithm.\n",
            "    \n",
            "    Args:\n",
            "        arr (list): A sorted list of elements to search through\n",
            "        target: The value to search for in the array\n",
            "        left (int): Left boundary of the search space (default: 0)\n",
            "        right (int): Right boundary of the search space (default: len(arr) - 1)\n",
            "    \n",
            "    Returns:\n",
            "        int: The index of the target element if found, otherwise -1\n",
            "    \n",
            "    Time Complexity: O(log n)\n",
            "    Space Complexity: O(log n) due to recursion stack\n",
            "    \"\"\"\n",
            "    \n",
            "    # Initialize right pointer on first call\n",
            "\n"
          ]
        }
      ],
      "source": [
        "response = litellm.completion(\n",
        "    model=\"cerebras/qwen-3-coder-480b\",\n",
        "    api_key=api_key,\n",
        "    api_base=\"https://api.cerebras.ai/v1\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Write a Python function to implement a binary search algorithm with detailed comments.\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0.2,\n",
        "    max_tokens=700\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['message']['content'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqSd4oBzpqAu"
      },
      "source": [
        "### Example 3: Comparing Multiple Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cl64p6qIppc8",
        "outputId": "73cdf1ac-0e2b-4ef5-ed7e-fac86b570495"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Model: cerebras/llama3.3-70b\n",
            "============================================================\n",
            "Functional Programming\n",
            "======================\n",
            "### Key Features\n",
            "\n",
            "The following are the key features of functional programming:\n",
            "\n",
            "1. **Immutable Data**: Data is never changed in place. Instead, new data structures are created each time the data needs to be updated.\n",
            "2. **Pure Functions**: Functions have no side effects and always return the same output given the same inputs.\n",
            "3. **Functions as First-Class Citizens**: Functions can be passed as arguments to other functions, returned as values from functions, and stored in data structures.\n",
            "4. **Higher-Order Functions**: Functions that take other functions as arguments or return functions as output.\n",
            "5. **Recursion**: A programming technique where a function calls itself to solve a problem.\n",
            "6. **Referential Transparency**: The output of a function depends only on its inputs and not on any external state.\n",
            "7. **Lazy Evaluation**: Expressions are only evaluated when their values are actually needed.\n",
            "8. **Type Systems**: Functional programming languages often have strong, static type systems to ensure the correctness of code.\n",
            "\n",
            "### Benefits\n",
            "\n",
            "The key features of functional programming provide several benefits, including:\n",
            "\n",
            "* **Easier Code Composition**: Functions can be combined to create new functions, making it easier to write modular and reusable code.\n",
            "* **Improved Code Readability**: Immutable data and pure functions make it easier to understand and predict the behavior of code.\n",
            "* **Better Support for Parallelism**: Immutable data and pure functions make it easier to write parallel code that is free from race conditions and other concurrency\n",
            "\n",
            "============================================================\n",
            "Model: cerebras/qwen-3-coder-480b\n",
            "============================================================\n",
            "Here are the key features of functional programming:\n",
            "\n",
            "## Core Principles\n",
            "\n",
            "**1. Pure Functions**\n",
            "- Functions that always return the same output for the same input\n",
            "- No side effects (don't modify external state)\n",
            "- Easier to test, debug, and reason about\n",
            "\n",
            "**2. Immutability**\n",
            "- Data structures cannot be modified after creation\n",
            "- Instead of changing data, new data structures are created\n",
            "- Eliminates many bugs related to shared mutable state\n",
            "\n",
            "**3. First-Class and Higher-Order Functions**\n",
            "- Functions can be assigned to variables, passed as arguments, and returned from other functions\n",
            "- Enables powerful abstractions and function composition\n",
            "\n",
            "## Key Concepts\n",
            "\n",
            "**4. Function Composition**\n",
            "- Building complex functions by combining simpler ones\n",
            "- Creating pipelines of transformations\n",
            "- Example: `f(g(h(x)))` instead of sequential steps\n",
            "\n",
            "**5. Declarative Style**\n",
            "- Focus on *what* you want to achieve rather than *how*\n",
            "- Emphasizes expressions over statements\n",
            "- More readable and closer to mathematical notation\n",
            "\n",
            "**6. Recursion**\n",
            "- Functions that call themselves to solve problems\n",
            "- Often replaces traditional loops\n",
            "- Natural fit for working with immutable data\n",
            "\n",
            "## Advanced Features\n",
            "\n",
            "**7. Lazy Evaluation**\n",
            "- Expressions are evaluated only when needed\n",
            "- Enables infinite data structures and efficient processing\n",
            "- Common in languages like Haskell\n",
            "\n",
            "**8. Referential Transparency**\n",
            "- Any expression can be replaced with its value without changing program behavior\n",
            "-\n",
            "\n",
            "============================================================\n",
            "Model: cerebras/gpt-oss-120b\n",
            "============================================================\n",
            "**Functional programming (FP)** is a programming paradigm that treats computation as the evaluation of mathematical functions and avoids changing state and mutable data. Below are its most important characteristics, each explained with a short example or illustration.\n",
            "\n",
            "---\n",
            "\n",
            "## 1. Pure Functions\n",
            "- **Definition:** A function whose return value depends **only** on its input arguments and has **no side‑effects** (doesn’t modify global state, I/O, or mutable data).\n",
            "- **Why it matters:** Pure functions are easier to reason about, test, and parallelize.\n",
            "- **Example (Haskell):**\n",
            "\n",
            "  ```haskell\n",
            "  add :: Int -> Int -> Int\n",
            "  add x y = x + y          -- No mutation, no I/O\n",
            "  ```\n",
            "\n",
            "  The same inputs (`2, 3`) will always produce `5`.\n",
            "\n",
            "---\n",
            "\n",
            "## 2. Immutability\n",
            "- **Definition:** Data structures cannot be altered after they are created; instead, “updates” produce new structures.\n",
            "- **Why it matters:** Eliminates bugs caused by unexpected mutation and enables safe sharing of data across threads.\n",
            "- **Example (Clojure):**\n",
            "\n",
            "  ```clojure\n",
            "  (def v [1\n"
          ]
        }
      ],
      "source": [
        "models = [\n",
        "    \"cerebras/llama3.3-70b\",\n",
        "    \"cerebras/qwen-3-coder-480b\",\n",
        "    \"cerebras/gpt-oss-120b\"\n",
        "]\n",
        "\n",
        "prompt = \"What are the key features of functional programming?\"\n",
        "\n",
        "for model in models:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Model: {model}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    response = litellm.completion(\n",
        "        model=model,\n",
        "        api_key=api_key,\n",
        "        api_base=\"https://api.cerebras.ai/v1\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.6,\n",
        "        max_tokens=300\n",
        "    )\n",
        "\n",
        "    print(response['choices'][0]['message']['content'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDLYeq9hnAWT"
      },
      "source": [
        " ### Example 4: Code Debugging with Qwen Coder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQWHP8CWnIkZ",
        "outputId": "68427693-aa06-49a2-cb23-aee7c0bb8be3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Code:\n",
            "\n",
            "def calculate_average(numbers):\n",
            "    total = 0\n",
            "    for num in numbers:\n",
            "        total += num\n",
            "    return total / len(numbers)\n",
            "\n",
            "result = calculate_average([1, 2, 3, 4, 5])\n",
            "print(result)\n",
            "\n",
            "\n",
            "Improved Version:\n",
            "## Analysis of the Original Code\n",
            "\n",
            "The original `calculate_average` function has several issues with edge cases and error handling:\n",
            "\n",
            "### Problems Identified:\n",
            "1. **Division by zero**: When an empty list is passed, `len(numbers)` returns 0, causing a `ZeroDivisionError`\n",
            "2. **No input validation**: The function doesn't check if the input is actually iterable\n",
            "3. **No type checking**: Non-numeric values in the list will cause a `TypeError`\n",
            "4. **No handling of None input**: Passing `None` will result in a `TypeError`\n",
            "\n",
            "## Improved Version\n",
            "\n",
            "Here's a robust version with comprehensive error handling:\n",
            "\n",
            "```python\n",
            "def calculate_average(numbers):\n",
            "    \"\"\"\n",
            "    Calculate the average of a list of numbers.\n",
            "    \n",
            "    Args:\n",
            "        numbers: An iterable containing numeric values\n",
            "        \n",
            "    Returns:\n",
            "        float: The average of the numbers\n",
            "        \n",
            "    Raises:\n",
            "        TypeError: If numbers is None or contains non-numeric values\n",
            "        ValueError: If numbers is empty\n",
            "        TypeError: If numbers is not iterable\n",
            "    \"\"\"\n",
            "    # Check if input is None\n",
            "    if numbers is None:\n",
            "        raise TypeError(\"Input cannot be None\")\n",
            "    \n",
            "    # Check if input is iterable\n",
            "    try:\n",
            "        # Convert to list to handle generators and other iterables\n",
            "        numbers_list = list(numbers)\n",
            "    except TypeError:\n",
            "        raise TypeError(\"Input must be an iterable (list, tuple, etc.)\")\n",
            "    \n",
            "    # Check if the list is empty\n",
            "    if len(numbers_list) == 0:\n",
            "        raise ValueError(\"Cannot calculate average of an empty list\")\n",
            "    \n",
            "    # Validate that all elements are numeric\n",
            "    for i, num in enumerate(numbers_list):\n",
            "        if not isinstance(num, (int, float, complex)):\n",
            "            raise TypeError(f\"All elements must be numeric. Element at index {i} is not a number: {num}\")\n",
            "    \n",
            "    # Calculate the average\n",
            "    total = sum(numbers_list)  # Using built-in sum() is more efficient\n",
            "    return total / len(numbers_list)\n",
            "\n",
            "# Test cases with error handling\n",
            "def test_calculate_average():\n",
            "    try:\n",
            "        # Normal case\n",
            "        result = calculate_average([1, 2, 3, 4, 5])\n",
            "        print(f\"Average: {result}\")\n",
            "        \n",
            "        # Edge cases\n",
            "        print(f\"Single element: {calculate_average([42])}\")\n",
            "        print(f\"Float numbers: {calculate_average([1.5, 2.5, 3.0])}\")\n",
            "        print(f\"Negative numbers: {calculate_average([-1, -2, -3])}\")\n",
            "        \n",
            "        # Error cases\n",
            "        calculate_average([])  # Empty list\n",
            "    except ValueError as e:\n",
            "        print(f\"ValueError: {e}\")\n",
            "    \n",
            "    try:\n",
            "        calculate_average(None)  # None input\n",
            "    except TypeError as e:\n",
            "        print(f\"TypeError: {e}\")\n",
            "    \n",
            "    try:\n",
            "        calculate_average([1, 2,\n"
          ]
        }
      ],
      "source": [
        "buggy_code = '''\n",
        "def calculate_average(numbers):\n",
        "    total = 0\n",
        "    for num in numbers:\n",
        "        total += num\n",
        "    return total / len(numbers)\n",
        "\n",
        "result = calculate_average([1, 2, 3, 4, 5])\n",
        "print(result)\n",
        "'''\n",
        "\n",
        "prompt = f\"\"\"Analyze this Python code and suggest improvements for edge cases and error handling:\n",
        "\n",
        "{buggy_code}\n",
        "\n",
        "Provide an improved version with better error handling.\"\"\"\n",
        "\n",
        "response = litellm.completion(\n",
        "    model=\"cerebras/qwen-3-coder-480b\",\n",
        "    api_key=api_key,\n",
        "    api_base=\"https://api.cerebras.ai/v1\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    temperature=0.3,\n",
        "    max_tokens=600\n",
        ")\n",
        "\n",
        "print(\"Original Code:\")\n",
        "print(buggy_code)\n",
        "print(\"\\nImproved Version:\")\n",
        "print(response['choices'][0]['message']['content'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOt4xPzVKByj"
      },
      "source": [
        "### Example 5: Different Temperature Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hgetmnJKByj",
        "outputId": "aa34a825-b681-4f7d-cb49-765ffbafc79f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Temperature: 0.1 ---\n",
            "As the last remnants of sunlight faded from the ravaged horizon, a lone spaceship, its hull etched with the scars of a thousand midnights, emerged from the depths of a nebula, carrying with it the whispers of a forgotten civilization and the echoes of a prophecy that would soon shatter the fragile balance of the galaxy.\n",
            "\n",
            "--- Temperature: 0.5 ---\n",
            "As the last remnants of sunlight faded from the ravaged horizon, a lone spaceship, its hull etched with the scars of a thousand midnights, emerged from the depths of a nebula, bearing a cargo of forbidden memories and a crew that was not entirely its own.\n",
            "\n",
            "--- Temperature: 0.9 ---\n",
            "As the last star in the universe died, its final whisper echoed through the void, a faint hum that awakened an ancient, cryogenically frozen city on a planet shrouded in an eternal, impenetrable twilight.\n"
          ]
        }
      ],
      "source": [
        "temperatures = [0.1, 0.5, 0.9]\n",
        "prompt = \"Write a creative opening line for a science fiction story.\"\n",
        "\n",
        "for temp in temperatures:\n",
        "    print(f\"\\n--- Temperature: {temp} ---\")\n",
        "\n",
        "    response = litellm.completion(\n",
        "        model=\"cerebras/llama3.3-70b\",\n",
        "        api_key=api_key,\n",
        "        api_base=\"https://api.cerebras.ai/v1\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=temp,\n",
        "        max_tokens=100\n",
        "    )\n",
        "\n",
        "    print(response['choices'][0]['message']['content'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPcVjV0fKByj"
      },
      "source": [
        "### Example 6: Batch Processing Multiple Queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCTt0UEVKByj",
        "outputId": "2d967552-3f04-45d6-8186-f4379a0d1b89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch Processing Results:\n",
            "\n",
            "\n",
            "1. Query: What is machine learning?\n",
            "Answer: **Machine Learning Definition**\n",
            "\n",
            "Machine learning is a subset of artificial intelligence (AI) that involves training algorithms to learn from data and make predictions or decisions without being explicitly programmed. It enables systems to improve their performance on a task over time, based on the data they receive.\n",
            "\n",
            "**Key Characteristics:**\n",
            "\n",
            "1. **Data-driven**: Machine learning relies on large amounts of data to learn patterns and relationships.\n",
            "2. **Algorithmic**: Machine learning uses algorithms to analyze data and make predictions or decisions.\n",
            "3. **Adaptive**: Machine learning systems can adapt to new data and improve their performance over time.\n",
            "4. **Autonomous**: Machine learning systems can operate independently, without human intervention.\n",
            "\n",
            "**Types of Machine Learning:**\n",
            "\n",
            "1. **Supervised Learning**:\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "2. Query: Explain neural networks.\n",
            "Answer: **Introduction to Neural Networks**\n",
            "=====================================\n",
            "\n",
            "Neural networks are a fundamental concept in machine learning and artificial intelligence. They are designed to mimic the structure and function of the human brain, allowing computers to learn from data and make predictions or decisions.\n",
            "\n",
            "**Basic Components**\n",
            "--------------------\n",
            "\n",
            "A neural network consists of the following basic components:\n",
            "\n",
            "1. **Artificial Neurons (Nodes)**: These are the basic building blocks of a neural network. Each node receives one or more inputs, performs a computation on those inputs, and then sends the output to other nodes.\n",
            "2. **Connections (Edges)**: These are the links between nodes, which allow them to exchange information.\n",
            "3. **Activation Functions**: These are mathematical functions that are applied to the output of\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "3. Query: What is deep learning?\n",
            "Answer: **Deep Learning Overview**\n",
            "==========================\n",
            "\n",
            "Deep learning is a subset of machine learning that involves the use of artificial neural networks to analyze and interpret data. It is called \"deep\" because it uses multiple layers of neural networks to learn complex patterns in data.\n",
            "\n",
            "**Key Characteristics:**\n",
            "\n",
            "* **Artificial Neural Networks**: Deep learning models are based on artificial neural networks, which are composed of layers of interconnected nodes (neurons) that process and transmit information.\n",
            "* **Multiple Layers**: Deep learning models use multiple layers of neural networks to learn complex patterns in data. Each layer learns to recognize a specific feature or pattern in the data.\n",
            "* **Hierarchical Representation**: Deep learning models learn to represent data in a hierarchical manner, with early layers learning to recognize\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "4. Query: Define artificial intelligence.\n",
            "Answer: Artificial intelligence (AI) refers to the development of computer systems that can perform tasks that typically require human intelligence, such as:\n",
            "\n",
            "1. Learning: The ability to learn from data, experiences, and environments.\n",
            "2. Reasoning: The ability to draw inferences, make decisions, and solve problems.\n",
            "3. Problem-solving: The ability to identify and resolve complex problems.\n",
            "4. Perception: The ability to interpret and understand data from sensors, such as images, speech, and text.\n",
            "5. Language understanding: The ability to comprehend and generate human language.\n",
            "\n",
            "AI systems use algorithms, statistical models, and computer programs to mimic human cognition and perform tasks that would normally require human intelligence. These systems can be categorized into two main types:\n",
            "\n",
            "1. **\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "5. Query: What is natural language processing?\n",
            "Answer: **Natural Language Processing (NLP)** is a subfield of artificial intelligence (AI) that deals with the interaction between computers and humans in natural language. It is a multidisciplinary field that combines computer science, linguistics, and cognitive psychology to enable computers to process, understand, and generate human language.\n",
            "\n",
            "**Key Aspects of NLP:**\n",
            "\n",
            "1. **Text Processing**: NLP involves processing and analyzing text data, including tokenization, stemming, and lemmatization.\n",
            "2. **Language Understanding**: NLP aims to enable computers to understand the meaning and context of human language, including syntax, semantics, and pragmatics.\n",
            "3. **Language Generation**: NLP also involves generating human-like language, including text, speech,\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "queries = [\n",
        "    \"What is machine learning?\",\n",
        "    \"Explain neural networks.\",\n",
        "    \"What is deep learning?\",\n",
        "    \"Define artificial intelligence.\",\n",
        "    \"What is natural language processing?\"\n",
        "]\n",
        "\n",
        "print(\"Batch Processing Results:\\n\")\n",
        "\n",
        "for i, query in enumerate(queries, 1):\n",
        "    print(f\"\\n{i}. Query: {query}\")\n",
        "\n",
        "    response = litellm.completion(\n",
        "        model=\"cerebras/llama3.3-70b\",\n",
        "        api_key=api_key,\n",
        "        api_base=\"https://api.cerebras.ai/v1\",\n",
        "        messages=[{\"role\": \"user\", \"content\": query}],\n",
        "        temperature=0.5,\n",
        "        max_tokens=150\n",
        "    )\n",
        "\n",
        "    print(f\"Answer: {response['choices'][0]['message']['content']}\")\n",
        "    print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C4DPpLGoYVf"
      },
      "source": [
        "###Building a Simple Chatbot with LiteLLM 🚅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mxWqVACoge3",
        "outputId": "3f72c299-c89c-4ff4-a047-f55a400d2506"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cerebras Chatbot: Hello! Type 'exit' to end the conversation.\n",
            "\n",
            "You: hi\n",
            "Chatbot: Hello. How can I assist you today?\n",
            "You: exit\n",
            "Chatbot: Goodbye! 👋\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import litellm\n",
        "\n",
        "print(\"Cerebras Chatbot: Hello! Type 'exit' to end the conversation.\\n\")\n",
        "\n",
        "chat_history = []\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "\n",
        "    if user_input.lower() == \"exit\":\n",
        "        print(\"Chatbot: Goodbye! 👋\")\n",
        "        break\n",
        "\n",
        "    chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    try:\n",
        "        response = litellm.completion(\n",
        "            model=\"cerebras/llama3.3-70b\",\n",
        "            api_key=api_key,\n",
        "            api_base=\"https://api.cerebras.ai/v1\",\n",
        "            messages=chat_history,\n",
        "            temperature=0.7,\n",
        "            max_tokens=500,\n",
        "        )\n",
        "\n",
        "        reply = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "        print(\"Chatbot:\", reply)\n",
        "\n",
        "        chat_history.append({\"role\": \"assistant\", \"content\": reply})\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", str(e))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlhlVcW0KByk"
      },
      "source": [
        "### Advanced: Using LiteLLM with Multiple Providers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2t6rxEnhKByk",
        "outputId": "88c108d8-fda8-4159-d327-755ce1adf0e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trying primary model: cerebras/llama3.3-70b\n",
            "\n",
            "Response:\n",
            "Recursion in Programming\n",
            "========================\n",
            "\n",
            "Recursion is a fundamental concept in programming where a function calls itself repeatedly until it reaches a base case that stops the recursion. This technique is used to solve problems that can be broken down into smaller sub-problems of the same type.\n",
            "\n",
            "Key Components of Recursion\n",
            "----------------------------\n",
            "\n",
            "1. **Base Case**: A condition that stops the recursion when met.\n",
            "2. **Recursive Call**: The function calls itself with a smaller input or a modified version of the original input.\n",
            "3. **State**: The current state of the function, including any local variables or parameters.\n",
            "\n",
            "How Recursion Works\n",
            "--------------------\n",
            "\n",
            "1. The function is called with an initial input.\n",
            "2. The function checks if the base case is met. If it is, the function returns a result.\n",
            "3. If the base case is not met, the function calls itself with a smaller input or a modified version of the original input.\n",
            "4. The recursive call creates a new instance of the function with its own local variables and parameters.\n",
            "5. Steps 2-4 repeat until the base case is met.\n",
            "6. Once the base case is met, the function returns a result, and the recursive calls unwind, returning results back up the call stack.\n",
            "\n",
            "Example: Factorial Function\n",
            "---------------------------\n",
            "\n",
            "```python\n",
            "def factorial(n):\n",
            "    # Base case: 1! = 1\n",
            "    if n == 1:\n",
            "        return 1\n",
            "    # Recursive call: n! = n *\n"
          ]
        }
      ],
      "source": [
        "def query_with_fallback(prompt, primary_model, fallback_model):\n",
        "    try:\n",
        "        print(f\"Trying primary model: {primary_model}\")\n",
        "        response = litellm.completion(\n",
        "            model=primary_model,\n",
        "            api_key=api_key,\n",
        "            api_base=\"https://api.cerebras.ai/v1\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.7,\n",
        "            max_tokens=300\n",
        "        )\n",
        "        return response['choices'][0]['message']['content']\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Primary model failed: {e}\")\n",
        "        print(f\"Trying fallback model: {fallback_model}\")\n",
        "\n",
        "        response = litellm.completion(\n",
        "            model=fallback_model,\n",
        "            api_key=api_key,\n",
        "            api_base=\"https://api.cerebras.ai/v1\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.7,\n",
        "            max_tokens=300\n",
        "        )\n",
        "        return response['choices'][0]['message']['content']\n",
        "\n",
        "prompt = \"Explain the concept of recursion in programming.\"\n",
        "result = query_with_fallback(\n",
        "    prompt,\n",
        "    primary_model=\"cerebras/llama3.3-70b\",\n",
        "    fallback_model=\"cerebras/gpt-oss-120b\"\n",
        ")\n",
        "\n",
        "print(\"\\nResponse:\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7_JA1_4KByk"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "This notebook demonstrated how to use Cerebras models with LiteLLM, including:\n",
        "\n",
        "1. Basic completion requests\n",
        "2. Streaming responses\n",
        "3. Code generation with specialized models\n",
        "4. Model comparison\n",
        "5. Temperature settings\n",
        "6. Batch processing\n",
        "7. Building a chatbot\n",
        "8. Fallback strategies\n",
        "\n",
        "LiteLLM provides a unified interface for accessing Cerebras's ultra-fast inference platform, making it easy to integrate into your applications."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
